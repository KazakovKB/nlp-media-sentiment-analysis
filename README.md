# NLP-Insight – сервис анализа тональности медиа-контента

## Описание проекта

Проект направлен на разработку интеллектуальной системы, которая анализирует тональность
и эмоции новостных публикаций и сообщений в медиапространстве. Решение позволит автоматически
отслеживать изменения общественных настроений, выявлять всплески негатива
и позитивные тренды, что поможет PR и аналитическим службам оперативно реагировать
на кризисные инфоповоды.

Сервис позволяет:
- регистрировать пользователей и аккаунты,
- подключать источники данных,
- запускать аналитические задания (jobs) по выбранным источникам и периодам,
- асинхронно обрабатывать данные с помощью ML-модели,
- просматривать агрегированные отчёты через UI и REST API.

Проект реализован с использованием FastAPI, PostgreSQL, RabbitMQ, Docker и асинхронных воркеров.

---

## Архитектура и доменная модель

Проект реализован в DDD-стиле с чётким разделением слоёв:

```
nlp-media-sentiment-analysis/
└── src/app/
    ├── api/        # REST API (FastAPI routers)
    ├── ui/         # HTML UI (Jinja2)
    ├── services/   # Application services (use-cases)
    ├── domain/     # Доменные сущности, value objects, контракты
    ├── infra/      # БД, ORM, MQ, UoW, репозитории
    ├── ml/         # ML-registry и загрузка моделей
    ├── worker/     # Асинхронные воркеры
    └── tests/      # Тесты
...
```

**Ключевые доменные сущности**
- User / Account — пользователи и аккаунты
- Source — глобальный источник данных
- AccountSource — ACL-связка аккаунта и источника
- Document — текстовый документ
- AnalysisJob — аналитическая задача
- OverviewReport — агрегированный отчёт по задаче

---

## Хранение данных 

- СУБД: PostgreSQL
- ORM: SQLAlchemy 2.x
- Миграции: Alembic
- Архитектурный паттерн: Unit of Work

Все данные (пользователи, источники, документы, задачи, отчёты) хранятся в БД.
Связь аккаунтов и источников реализована через ACL-таблицу account_sources.

---

## REST API

Сервис предоставляет полноценный REST API:

**Аутентификация**
```
POST /api/auth/register
POST /api/auth/login
```

**Аналитика**
```
POST /api/analysis/jobs
GET  /api/analysis/jobs
GET  /api/analysis/jobs/{id}
GET  /api/analysis/jobs/{id}/overview
```

**Источники**
```
GET /api/sources
GET /api/sources/{id}/stats
```

**Документация доступна через Swagger UI:**
```
/docs
```

---

## Пользовательский интерфейс

UI реализован на базе FastAPI + Jinja2:
- /login, /register — аутентификация
- /sources — список источников
- /analysis/new — создание аналитической задачи
- /jobs — список задач
- /jobs/{id} — детальная страница задачи и отчёта

UI и API используют одну и ту же бизнес-логику, без дублирования.

---

## Тестирование

Реализованы автотесты для критических сценариев:
- создание аналитической задачи,
- валидация scope,
- обработка пустых периодов,
- happy-path выполнения job и генерации отчёта.

Используется:
- pytest
- httpx
- изолированная PostgreSQL-БД в Docker

Тесты находятся в src/app/tests.

---

## Docker и инфраструктура

Проект полностью контейнеризирован:
- app — FastAPI приложение
- worker — ML-воркеры
- db — PostgreSQL
- rabbitmq — брокер сообщений

**Запуск проекта**
```
make up
```

**Остановка**
```
make down
```

---

## Масштабирование воркеров

Обработка аналитических задач выполняется асинхронно:
- API кладёт job_id в RabbitMQ
- воркеры получают задания из очереди
- каждый воркер независимо обрабатывает job

Количество воркеров масштабируется горизонтально:
```
docker compose up --scale worker=4
```

---

## ML-интеграция

- Используется кастомная модель на базе RuBERT-tiny2
- Загрузка модели вынесена в ml/registry
- Возможна замена модели без изменения бизнес-логики
- Для стабильности реализован fallback-режим

---

## Технологический стек

- FastAPI
- SQLAlchemy
- PostgreSQL
- RabbitMQ
- Docker / Docker Compose
- PyTorch
- pytest
- Jinja2